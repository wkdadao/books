1. Kruskal， 最小生成树（MST， Minimum Spanning Tree）
	切分定理 (Cut Property)

	在任意切分中，最小的跨切分边一定属于某个 MST。
	Kruskal 的每一步，其实就是找一个切分（由并查集分出的集合）并选择最小跨边 → 符合切分定理。
	👉 说明 Kruskal 每次的选择都是安全的。
	
2. Dijkstra 算法（单源最短路，非负权）

3. Perfect Binary Tree， complete Binary Tree， Full Binary Tree

4. “前缀无歧义编码” （prefix-free code） ，简称PFC编码。 哈夫曼树（Huffman tree）

5. preorder, inorder, postorder interate binary tree

6. BFS, DFS
	堆版 Dijkstra： 
	0-1BFS： 对权为 0 的边 push_front，权为 1 的边 push_back，无需堆/Decrease-Key。 特殊版的堆版 Dijkstra
	Dial 算法＝“桶式 Dijkstra”
	
	选型速决（面试话术）
	题目含“最少步数/最短边数/最少转换次数/距离 k” → 先上 BFS（必要时多源/双向/0-1 变体）。
	需要枚举解或约束满足（组合/排列/分割/数独/图着色）→ DFS 回溯（选→撤销，配剪枝）。
	结构性质（有向环/拓扑/桥/割点/SCC）→ DFS 家族（颜色标记、Tarjan/Kosaraju）。
	边有权：全为 0/1 → 0-1 BFS；正权非负 → Dijkstra；可负权 → Bellman-Ford/SPFA。
	输入可能很深/N 可达 1e5 → 少用递归 DFS，写显式栈；BFS 也要严控 visited 与剪枝。
	
7. 拓扑排序（topological sorting）， DAG 是 Directed Acyclic Graph
	DFS搜索善于检测环路的特性，恰好可以用来判别输入是否为有向无环图。具体地，搜索过程中一旦发现后向边，即可终止算法并报告“因非DAG而无法拓扑排序”	
	多个起点/终点：按上法天然支持；也可加虚拟源/汇（工期 0）统一处理。
	“关键路径”（Critical Path, CPM）就是在 DAG 上用拓扑排序做最长路：
	1. 正向加反向拓扑排序
	2. 找最长的路。记录每个节点的开始结束时间。关键路径上的下游节点开始时间就是上游节点的结束时间。 只想拿到“一条”关键路径 → 可以不做反向推导	
	
8. 双连通域分解
	考查无向图G。若删除顶点v后G所包含的连通域增多，则v称作切割节点（cut vertex） 或 关节点（articulation point）
	可行算法。 DFS树的根节点若至少拥有两个分支。for v -> u, low [u] >= dfn[v]
	
9. 每一种选取策略都等效于， 给所有顶点赋予不同的优先级， 而且随着算法的推进不断调整；
	而每一步迭代所选取的顶点， 都是当时的优先级最高者。按照这种理解，包括BFS和DFS在内的
	几乎所有图搜索，都可纳入统一的框架。 鉴于优先级在其中所扮演的关键角色，故亦称作优先级
	搜索（priority-first search, PFS） ， 或最佳优先搜索（best-first search, BFS） 。
	BFS搜索会优先考查更早被发现的顶点，而DFS搜索则恰好相反，会优先考查最后被发现的顶点。
	
10. 最小支撑树（ minimum spanning tree, MST）
	1. Kruskal 算法（边视角，适合稀疏图）
	思想：从小到大排序边，一条条尝试加入，只要不会形成环就加入。
	使用 并查集（Union-Find） 判断环
	时间复杂度：O(E log E， 排序所用)，E 是边数
	流程
	所有边按权重升序排列
	初始化每个顶点为一个集合（并查集）
	遍历每条边，如果两端不属于同一集合，就加入 MST 并合并集合

	2. Prim 算法（点视角，适合稠密图）
	思想：从某个点出发，每次选择连接当前树的最短边。
	可用堆（优先队列）优化选边 （类似于, Dijkstra堆）
	时间复杂度：O(E log V)，V 是顶点数
	流程：
	任意选择一个起点，加入树
	每次从未加入的点中，选出与树连接的最小边
	重复直到所有点加入树

11. 单源：
	Dijkstra 算法， priority_queue（最小堆）， 0-1 BFS， Dial 算法
	Bellman-Ford 算法 ， 
	SPFA 算法（Bellman-Ford优化）， 最短路径 = 权重之和最小 , 充分考虑边权影响 ，SPFA 是 BFS 的“带权版”+ Bellman-Ford 的“高效版”，它借鉴了 BFS 的“按需扩展”思想，但服务于有权图的最短路径计算。
	BFS， 最短路径 = 最少边数， 不处理边权 
	
	多源：
	Floyd-Warshall 是一个三重循环的动态规划算法， 三个维度： 允许使用的“中间点”编号 ≤ k， 起点， 终点
	f[k][i][j] = 从 i 到 j 的最短路径，允许中间点编号 ≤ k， 
	实际实现中，为节省空间，我们用一个二维数组 dis[i][j] 滚动更新，所以只保留当前版本，不保留历史版本。
	
	
12. 为何 -log(rate) 为权重
	将汇率乘积变为负对数加和，核心目的是把“套利路径乘积 > 1”问题转为“路径加和 < 0”的负环检测问题，让图论算法可以直接应用。
	
	USD → EUR : 0.9
	EUR → JPY : 130
	JPY → USD : 0.0087
	0.9 × 130 × 0.0087 = 1.0179
	
	w₁ = -ln(0.9)     ≈ 0.1054  
	w₂ = -ln(130)     ≈ -4.8675  
	w₃ = -ln(0.0087)  ≈ 4.7449

	路径总权重 = w₁ + w₂ + w₃
			   = 0.1054 + (-4.8675) + 4.7449
			   = -0.0172
	判断乘积 > 1，等价于判断 -log(乘积) < 0
	
13. AVL,  伸展树（splay tree）, B-, B+, 红黑树，Treap (堆树)， 线段树（Segment Tree），哈希（不支持Key排序，也就不支持范围查找）
	📌 Treap 的基本思想
	Treap 结合了两种数据结构的性质：
	二叉搜索树 (BST) 性质
	对每个结点的 key 来说：
	左子树所有 key < 当前结点 key < 右子树所有 key。
	堆 (Heap) 性质
	对每个结点的 priority 来说（通常是随机生成的）：
	父结点的优先级比子结点更小（最小堆），或更大（最大堆）。
	也就是说：
	按照 key 来看，它是一棵 BST； 按照 priority 来看，它是一棵 堆。
	
14. 树状数组（Fenwick Tree）

15. 哈希表，
	如果你是想面试/工程里回答“知名哈希函数”，我建议这样分类回答：
	高性能非加密哈希：MurmurHash、CityHash、xxHash
	加密哈希：SHA-256、SHA-3、BLAKE2
	历史/经典：MD5、SHA-1、FNV
	
	开放定址（open addressing）指的是冲突解决策略：当某个位置被占用时，不会在桶里挂链表，而是继续在散列表中寻找下一个空位（例如线性探测、二次探测、双重哈希）。这样所有元素都“开”放在散列表的地址空间里，不需要额外指针或外部存储。
	闭散列（closed hashing） 这里“闭”的意思是元素只能放在散列表本身的槽位里，不能像**开散列（separate chaining）**那样在外部挂链表。
	所以名字有点让人困惑：
	open addressing = closed hashing（同一个东西的不同叫法）；
	separate chaining = open hashing（另一派的叫法）。
	flat_hash_map 和 unordered_map 采用的正是 开放定址 / 闭散列，区别于 std::unordered_map 默认的 拉链法 / 开散列。
	
16. 自研 slab/arena pool 固定大小块内存池，循环使用
	一页小抄（面试可用）
	分配：alloc(sizeof(T)) → placement new → 用完 ~T() → free(ptr)
	批处理：收集指针 → 全部 ~T() → resetArena()
	多线程：TLS 池，禁止跨线程 free；或设计 MPMC 安全回收通道
	封装：OrderPool / Pooled<T> 防漏
	接 STL：自定义 Allocator 或写 pmr::memory_resource 适配器
	监控：in-use/空闲/碎片率/慢路径
	
17. Bucket Sort： 桶排序：按区间范围放桶，一次搞定。 把数据按照值的范围划分到多个桶（bucket）里，每个桶内部再单独排序，最后把桶连接起来。
	Radix Sort： 基数排序：按数位放桶，反复搞定。
	
18. pip size和tick size
	两者都表示“价格最小变动单位”。
	pip 更像是一种市场习惯（外汇报价方式）；
	tick 是合约规则中硬性规定（期货/股票交易所定义）。
	在外汇期货中，pip size 和 tick size 往往可以对应起来，比如 1 pip = 1 tick，但严格来说是不同概念。
	
	pip size：外汇市场的“传统最小报价单位”。
	fractional pip / pipette：更高精度，行业已经普遍使用。
	tick size：如果在期货交易所（如CME外汇期货），必须严格遵守交易所规定的 tick，不可随意更细。
	
19. base point (bp) = 0.01%，常用于利率/收益率；

	| 名称                   | 缩写     | 定义                              		| 常见数值                                           | 应用场景                | 举例                                          |
	| ------------------- 	| ------ | ------------------------------- 			| ---------------------------------------------- | ------------------- | ------------------------------------------- |
	| **Pip（点）**          | –      | 外汇报价的最小单位（传统上 EUR/USD = 0.0001） | EUR/USD：1 pip = 0.0001<br>USD/JPY：1 pip = 0.01 | 外汇即期 (Spot FX)、外汇交易 | EUR/USD 从 **1.2000 → 1.2001** = 1 pip       |
	| **Pipette（亚pip）**   | –      | 1/10 pip，更高精度的报价                	| EUR/USD：0.00001                                | 高频交易，零售外汇平台常见       | EUR/USD 从 **1.20000 → 1.20001** = 1 pipette |
	| **Tick（最小变动价位）** | –      | 交易所规定的合约最小价格变动                  | CME ES期货：0.25 index points<br>黄金GC：0.10 USD    | 期货、股票、交易所衍生品        | ES期货从 **5000.00 → 5000.25** = 1 tick        |
	| **Basis Point（基点）**| **bp** | 0.01% = 0.0001（百分比的最小单位）        	| 1% = 100 bps                                   | 利率、收益率、信用利差         | 美联储加息 **25 bps = 0.25%**                    |

20. 小顶堆 (min-heap)， 大顶堆 (max-heap)
	堆：
	一定是 完全二叉树（每一层都填满，最后一层从左到右填）。
	存储时常用 数组（下标索引即可表示父子关系）。
	只保证 堆序性质（父 ≥ 子，或 父 ≤ 子）。
	二叉搜索树（BST）：
	不要求完全二叉树。
	必须满足：左子树所有值 < 根 < 右子树所有值。
	常用指针结构实现（左/右孩子指针）。
	
	左式堆（Leftist Heap）。它和普通的二叉堆不太一样，主要用于高效合并
	
21. 滚动哈希（Rolling Hash）算法， 
	又常被称为 Rabin–Karp 指纹更新公式，因为它最经典的应用就是 Rabin–Karp 字符串匹配算法。
	核心思想就是用一个多项式哈希，把子串的哈希在常数时间  T[k..k+m−1] 更新到 T[k+1..k+m]。

	powRm1  会溢出，但在 uint64_t 版滚动哈希里没关系，这是正常且安全的。如果用 % M 的那版，就必须防止溢出。 （powRm1 = (powRm1 * R) % M）
	uint64_t roll(uint64_t h, char head, char tail, uint64_t R, uint64_t powRm1) {
		h -= (uint64_t)(unsigned char)head * powRm1;
		h = h * R + (unsigned char)tail;
		return h; // 自然溢出当模 2^64
	}
	
22. KMP算法（重点）
	LPS = Longest Proper Prefix which is also Suffix， 最长的既是前缀又是后缀的子串长度。
	
23. 排序：
	快速排序（Quick Sort）面试重点
	为什么快排通常最快？
	缓存友好：快排访问模式连续，局部性好，能充分利用 CPU 缓存。
	原地排序：空间复杂度 O(log n)，避免大量额外内存（相比归并 O(n)）。
	分治递归：平均情况下，能将问题分为两半，复杂度 O(n log n)。
	实际表现：在大多数随机数据、工程场景里，快排比归并、堆排更快（常数小）。
	
	如何避免退化到 O(n²)？
	随机化枢轴：随机选择一个元素作为 pivot（防止对手构造数据攻击）。
	三数取中（median-of-three）： 从头、中、尾三个元素中选中位数作为 pivot，提高平衡性。
	三路快排（Dutch National Flag 变种）：处理大量重复元素时避免退化（如 [2,2,2,2,2...]）。 将数组分成 < pivot, = pivot, > pivot 三段。
	
	归并排序（Merge Sort）面试重点
	1. 核心思想
	分治（Divide and Conquer）
	把数组拆分成两半；
	分别递归排序；
	合并两个有序子序列。
	递归树高度 log n，每一层合并 O(n)，所以整体复杂度 O(n log n)。

	2. 高频考察点
	✅ 1. 归并排序的稳定性
	合并时，如果 arr[i] == arr[j]，优先选择左边的元素进入结果。
	这样能保持相对顺序 → 归并排序是稳定的排序。
	👉 面试回答模板：
	“在合并时，遇到相等元素保持左边在前，因此归并排序是稳定排序，适用于对稳定性有要求的场景（比如交易流水按金额再按时间排序）。”

	. 外部排序
	当数据太大无法全部放入内存时：
	把数据分块读入内存，各自排序；
	将多个有序块进行多路归并。
	👉 面试回答模板：
	“归并排序可以天然扩展为外部排序，通过多路归并合并磁盘上的有序块，适合处理海量数据。”
	
	数组用快排，链表用合并
	
	std::sort 需要 随机访问迭代器（array / vector），而 list 迭代器只是双向迭代器。必须用 list.sort()， 是归并排序。
	
	3. 堆排序
	堆排序要点速览
	堆：完全二叉树，父节点 ≥（或 ≤）子节点。最大堆用于升序堆排。
	数组存堆（0 基）：left=2*i+1，right=2*i+2，parent=(i-1)/2
	堆排序：buildHeap(O(n)) → 反复取堆顶并下滤(O(log n) each) → 总 O(n log n)
	空间：O(1) 原地；稳定性：不稳定
	
	二、如何在 O(n) 建堆（Floyd 的自底向上建堆）
	思想：不用逐个“上滤”（那是 O(n log n)）。而是从最后一个非叶子结点开始，逐个“下滤”（sift-down） 到根。
	
	求最大的 K 个元素（最常见）， 用 大小为 K 的“最小堆” 维护候选， 建堆 O(K) + 扫描 (n−K) 次，每次 O(log K) → O(n log K)
	
	与 partial_sort / nth_element 的取舍？
	只要 Top-K 集合：std::nth_element 平均 O(n) 更快；
	需要 随流在线维护 或 K 很小：堆 更合适；
	需要 有序 Top-K 列表：partial_sort（O(n log K)）或 堆后再排序。
	
	4. std::sort, std::stable_sort(合并，额外空间)
	“要让快排看起来稳定，我会在比较器里把原始下标作为次关键字（value 相等时比较 idx）。实现上可用间接排序 idx 数组，或把元素装饰为 (value, index)。不建议改写原值来编码位置，因为会改变语义并引入溢出/精度风险。
	若允许额外空间，std::stable_sort 是更直接的选择。”
	
	为什么插入排序在数据几乎有序时很快？
	插入排序的复杂度和“逆序数(inversion)”成正比。数组几乎有序时，逆序数很少，所以每次插入都只需少量移动，总体接近 O(n)。这时插入排序甚至比 O(n log n) 的快排还快，因此很多库在小规模或近乎有序时会切换到插入排序。
	
	5. 计数排序 / 基数排序 / 桶排序
	用于面试时展示“突破 O(n log n) 的下界”。
	面试常问：
	“如何在 O(n) 时间内排序 10 万个成绩（0~100 分）？”
	“如何对定长字符串排序？”
	
	6. 为什么希尔排序能比 O(n²) 更快？
	核心：先让元素大幅度移动，减少总的移动次数。
	如果 gap 缩得太慢（比如每次只减 1）：几乎退化成插入排序 → O(n²)。
	如果 gap 缩得太快（比如 100→1）：就只做了两次排序，效果有限。
	
	7. std::partial_sort 是 C++ STL 提供的一个排序算法，用来把区间 [first, last) 中前 middle - first 个元素排好序（升序或按比较器规则），而剩余的元素不保证有序。